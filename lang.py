import re
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB

# -----------------------------
# 1. CREATE DATASET (10 LANGUAGES)
# -----------------------------
data = {
    "text": [
        # English
        "hello how are you",
        "i love machine learning",
        "python is very powerful",
        "this project predicts language",
        "data science is interesting",

        # Spanish
        "hola como estas",
        "me gusta aprender programacion",
        "el aprendizaje automatico es interesante",
        "este proyecto detecta el idioma",
        "la ciencia de datos es fascinante",

        # French
        "bonjour comment ca va",
        "j aime apprendre la programmation",
        "l apprentissage automatique est interessant",
        "ce projet detecte la langue",
        "la science des donnees est fascinante",

        # German
        "hallo wie geht es dir",
        "ich liebe maschinelles lernen",
        "programmieren mit python macht spass",
        "dieses projekt erkennt die sprache",
        "datenwissenschaft ist sehr interessant",

        # Italian
        "ciao come stai",
        "mi piace programmare in python",
        "l apprendimento automatico e interessante",
        "questo progetto rileva la lingua",
        "la scienza dei dati e affascinante",

        # Hindi
        "рдирдорд╕реНрддреЗ рдЖрдк рдХреИрд╕реЗ рд╣реИрдВ",
        "рдореБрдЭреЗ рдорд╢реАрди рд▓рд░реНрдирд┐рдВрдЧ рдкрд╕рдВрдж рд╣реИ",
        "рдкрд╛рдпрдерди рдПрдХ рд╢рдХреНрддрд┐рд╢рд╛рд▓реА рднрд╛рд╖рд╛ рд╣реИ",
        "рдпрд╣ рдкрд░рд┐рдпреЛрдЬрдирд╛ рднрд╛рд╖рд╛ рдкрд╣рдЪрд╛рдирддреА рд╣реИ",
        "рдбреЗрдЯрд╛ рд╡рд┐рдЬреНрдЮрд╛рди рд░реЛрдЪрдХ рд╣реИ",

        # Marathi
        "рдирдорд╕реНрдХрд╛рд░ рддреБрдореНрд╣реА рдХрд╕реЗ рдЖрд╣рд╛рдд",
        "рдорд▓рд╛ рдорд╢реАрди рд▓рд░реНрдирд┐рдВрдЧ рдЖрд╡рдбрддреЗ",
        "рдкрд╛рдпрдерди рд╣реА рд╢рдХреНрддрд┐рд╢рд╛рд▓реА рднрд╛рд╖рд╛ рдЖрд╣реЗ",
        "рд╣рд╛ рдкреНрд░рдХрд▓реНрдк рднрд╛рд╖рд╛ рдУрд│рдЦрддреЛ",
        "рдбреЗрдЯрд╛ рд╕рд╛рдпрдиреНрд╕ рдЦреВрдк рд░реЛрдЪрдХ рдЖрд╣реЗ",

        # Tamil
        "ро╡рогроХрпНроХроорпН роирпАроЩрпНроХро│рпН роОрокрпНрокроЯро┐ роЗро░рпБроХрпНроХро┐ро▒рпАро░рпНроХро│рпН",
        "роОройроХрпНроХрпБ роорпЖро╖ро┐ройрпН ро▓рпЖро░рпНройро┐роЩрпН рокро┐роЯро┐роХрпНроХрпБроорпН",
        "рокрпИродрпНродро╛ройрпН роТро░рпБ роЪроХрпНродро┐ро╡ро╛ропрпНроирпНрод роорпКро┤ро┐",
        "роЗроирпНрод родро┐роЯрпНроЯроорпН роорпКро┤ро┐ропрпИ роХрогрпНроЯро▒ро┐роХро┐ро▒родрпБ",
        "роЯрпЗроЯрпНроЯро╛ роЪропро┐ройрпНро╕рпН рооро┐роХро╡рпБроорпН роЪрпБро╡ро╛ро░роЪро┐ропрооро╛ройродрпБ",

        # Telugu
        "р░ир░ор░╕р▒Нр░др▒З р░ор▒Ар░░р▒Б р░Ор░▓р░╛ р░Йр░ир▒Нр░ир░╛р░░р▒Б",
        "р░ир░╛р░Хр▒Б р░ор▒Жр░╖р░┐р░ир▒Н р░▓р▒Жр░░р▒Нр░ир░┐р░Вр░Чр▒Н р░Зр░╖р▒Нр░Яр░В",
        "р░кр▒Ир░ер░╛р░ир▒Н р░Тр░Х р░╢р░Хр▒Нр░др░┐р░╡р░Вр░др░ор▒Ир░и р░нр░╛р░╖",
        "р░И р░кр▒Нр░░р░╛р░Ьр▒Жр░Хр▒Нр░Яр▒Н р░нр░╛р░╖р░ир▒Б р░Чр▒Бр░░р▒Нр░др░┐р░╕р▒Нр░др▒Бр░Вр░жр░┐",
        "р░бр▒Зр░Яр░╛ р░╕р▒Ир░ир▒Нр░╕р▒Н р░Жр░╕р░Хр▒Нр░др░┐р░Хр░░р░Вр░Чр░╛ р░Йр░Вр░Яр▒Бр░Вр░жр░┐",

        # Urdu
        "█Б█М┘Д┘И ╪в┘╛ ┌й█М╪│█Т █Б█М┌║",
        "┘Е╪м┌╛█Т ┘Е╪┤█М┘Ж ┘Д╪▒┘Ж┘Ж┌п ┘╛╪│┘Ж╪п █Б█Т",
        "┘╛╪з╪ж╪к┌╛┘Ж ╪з█М┌й ╪╖╪з┘В╪к┘И╪▒ ╪▓╪и╪з┘Ж █Б█Т",
        "█М█Б ┘Е┘Ж╪╡┘И╪и█Б ╪▓╪и╪з┘Ж ┌й█М ╪┤┘Ж╪з╪о╪к ┌й╪▒╪к╪з █Б█Т",
        "┌И█М┘╣╪з ╪│╪з╪ж┘Ж╪│ ╪п┘Д┌Ж╪│┘╛ █Б█Т"
    ],

    "language": (
        ["English"] * 5 +
        ["Spanish"] * 5 +
        ["French"] * 5 +
        ["German"] * 5 +
        ["Italian"] * 5 +
        ["Hindi"] * 5 +
        ["Marathi"] * 5 +
        ["Tamil"] * 5 +
        ["Telugu"] * 5 +
        ["Urdu"] * 5
    )
}

df = pd.DataFrame(data)

# -----------------------------
# 2. CLEAN TEXT
# -----------------------------
def clean_text(text):
    text = text.lower()
    text = re.sub(r'\d+|http\S+|www\S+', '', text)
    text = re.sub(r'\s+', ' ', text).strip()
    return text

df["text"] = df["text"].apply(clean_text)

# -----------------------------
# 3. SCRIPT DETECTION (RULE-BASED)
# -----------------------------
def detect_script(text):
    if re.search(r'[рдЕ-рд╣]', text):
        return "Devanagari"
    elif re.search(r'[роЕ-ро╣]', text):
        return "Tamil"
    elif re.search(r'[р░Е-р░╣]', text):
        return "Telugu"
    elif re.search(r'[╪А-█┐]', text):
        return "Urdu"
    else:
        return "Latin"

# -----------------------------
# 4. VECTORIZE & TRAIN ML MODEL
# -----------------------------
vectorizer = TfidfVectorizer(
    analyzer="char_wb",
    ngram_range=(2, 5)
)

X = vectorizer.fit_transform(df["text"])
model = MultinomialNB()
model.fit(X, df["language"])

# -----------------------------
# 5. INTERACTIVE PREDICTION
# -----------------------------
print("\nЁЯМН HYBRID LANGUAGE DETECTION SYSTEM")
print("Rule-based Script Detection + ML Prediction")
print("Type a sentence and press Enter")
print("Type 'exit' to quit\n")

while True:
    sentence = input("ЁЯУЭ Enter sentence: ")

    if sentence.lower() == "exit":
        print("ЁЯСЛ Exiting...")
        break

    script = detect_script(sentence)
    print(f"ЁЯз╛ Script detected: {script}")

    cleaned = clean_text(sentence)
    vec = vectorizer.transform([cleaned])
    prediction = model.predict(vec)[0]

    print(f"тЬЕ Predicted Language: {prediction}\n")
